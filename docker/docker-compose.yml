# Base stack configuration for Myaku.
#
# Should be run with one of the dev, test, or prod docker-compose files to
# apply the approriate overrides for the environment the stack is being run in.

version: "3.7"
services:
  crawler:
    image: friedrice2/myaku_crawler:1.6.0
    volumes:
      - type: volume
        source: crawler_log
        target: /crawler/log
    environment:
      # A cron schedule of "#" will comment out the line for the crawl job in
      # the crontab file so that it will not run during testing.
      CRAWL_CRON_SCHEDULE: "#"
      CRAWLER_LIST: "Asahi,Kakuyomu"
      KAKUYOMU_CRAWLER_PAGE_TO_CRAWL: 5
      MYAKU_CRAWLDB_HOST: crawldb
      MYAKU_CRAWLDB_USERNAME_FILE: /run/secrets/crawldb_crawler_username
      MYAKU_CRAWLDB_PASSWORD_FILE: /run/secrets/crawldb_crawler_password
      MYAKU_FIRST_PAGE_CACHE_HOST: first-page-cache
      MYAKU_FIRST_PAGE_CACHE_PASSWORD_FILE: /run/secrets/first_page_cache_password
      MYAKU_NEXT_PAGE_CACHE_HOST: next-page-cache
      MYAKU_NEXT_PAGE_CACHE_PASSWORD_FILE: /run/secrets/next_page_cache_password
      DEBUG_LOG_MAX_SIZE: 209715200  # 200mb
      INFO_LOG_MAX_SIZE: 20971520 # 20mb
    secrets:
      - crawldb_crawler_username
      - crawldb_crawler_password
      - first_page_cache_password
      - next_page_cache_password
    networks:
      - crawler_net
  rescore:
    image: friedrice2/myaku_rescore:1.3.0
    volumes:
      - type: volume
        source: rescore_log
        target: /rescore/log
    environment:
      # A cron schedule of "#" will comment out the line for the rescore job in
      # the crontab file so that it will not run during testing.
      RESCORE_CRON_SCHEDULE: "#"
      MYAKU_CRAWLDB_HOST: crawldb
      MYAKU_CRAWLDB_USERNAME_FILE: /run/secrets/crawldb_crawler_username
      MYAKU_CRAWLDB_PASSWORD_FILE: /run/secrets/crawldb_crawler_password
      MYAKU_FIRST_PAGE_CACHE_HOST: first-page-cache
      MYAKU_FIRST_PAGE_CACHE_PASSWORD_FILE: /run/secrets/first_page_cache_password
      MYAKU_NEXT_PAGE_CACHE_HOST: next-page-cache
      MYAKU_NEXT_PAGE_CACHE_PASSWORD_FILE: /run/secrets/next_page_cache_password
      DEBUG_LOG_MAX_SIZE: 209715200  # 200mb
      INFO_LOG_MAX_SIZE: 20971520 # 20mb
    secrets:
      - crawldb_crawler_username
      - crawldb_crawler_password
      - first_page_cache_password
      - next_page_cache_password
    networks:
      - crawler_net
  web:
    image: friedrice2/myaku_web:1.7.0
    volumes:
      - type: volume
        source: web_log
        target: /myakuweb/log
    environment:
      MYAKU_CRAWLDB_HOST: crawldb
      MYAKU_CRAWLDB_USERNAME_FILE: /run/secrets/crawldb_web_username
      MYAKU_CRAWLDB_PASSWORD_FILE: /run/secrets/crawldb_web_password
      MYAKU_FIRST_PAGE_CACHE_HOST: first-page-cache
      MYAKU_FIRST_PAGE_CACHE_PASSWORD_FILE: /run/secrets/first_page_cache_password
      MYAKU_NEXT_PAGE_CACHE_HOST: next-page-cache
      MYAKU_NEXT_PAGE_CACHE_PASSWORD_FILE: /run/secrets/next_page_cache_password
      RABBIT_HOST: web-rabbit
      RABBIT_USERNAME_FILE: /run/secrets/web_rabbit_username
      RABBIT_PASSWORD_FILE: /run/secrets/web_rabbit_password
      MYAKUWEB_ALLOWED_HOSTS_FILE: /myakuweb_allowed_hosts
      DJANGO_SECRET_KEY_FILE: /run/secrets/web_django_secret_key
      DEBUG_LOG_MAX_SIZE: 209715200  # 200mb
      INFO_LOG_MAX_SIZE: 20971520 # 20mb
    configs:
      - myakuweb_allowed_hosts
    secrets:
      - crawldb_web_username
      - crawldb_web_password
      - web_django_secret_key
      - first_page_cache_password
      - next_page_cache_password
      - web_rabbit_username
      - web_rabbit_password
    networks:
      - web_net
  web-rabbit:
    image: rabbitmq:3.7.17
    hostname: web-rabbit
    environment:
      RABBITMQ_DEFAULT_USER_FILE: /run/secrets/web_rabbit_username
      RABBITMQ_DEFAULT_PASS_FILE: /run/secrets/web_rabbit_password
    secrets:
      - web_rabbit_username
      - web_rabbit_password
    networks:
      - web_net
  web-worker:
    image: friedrice2/myaku_web:1.7.0
    entrypoint:
      - celery
      - -A
      - myakuweb
      - worker
      - --loglevel
      - INFO
    volumes:
      - type: volume
        source: web_worker_log
        target: /myakuweb/log
    environment:
      MYAKU_CRAWLDB_HOST: crawldb
      MYAKU_CRAWLDB_USERNAME_FILE: /run/secrets/crawldb_web_username
      MYAKU_CRAWLDB_PASSWORD_FILE: /run/secrets/crawldb_web_password
      MYAKU_FIRST_PAGE_CACHE_HOST: first-page-cache
      MYAKU_FIRST_PAGE_CACHE_PASSWORD_FILE: /run/secrets/first_page_cache_password
      MYAKU_NEXT_PAGE_CACHE_HOST: next-page-cache
      MYAKU_NEXT_PAGE_CACHE_PASSWORD_FILE: /run/secrets/next_page_cache_password
      RABBIT_HOST: web-rabbit
      RABBIT_USERNAME_FILE: /run/secrets/web_rabbit_username
      RABBIT_PASSWORD_FILE: /run/secrets/web_rabbit_password
      MYAKUWEB_ALLOWED_HOSTS_FILE: /myakuweb_allowed_hosts
      DJANGO_SECRET_KEY_FILE: /run/secrets/web_django_secret_key
      DEBUG_LOG_MAX_SIZE: 209715200  # 200mb
      INFO_LOG_MAX_SIZE: 20971520 # 20mb
    configs:
      - myakuweb_allowed_hosts
    secrets:
      - crawldb_web_username
      - crawldb_web_password
      - web_django_secret_key
      - first_page_cache_password
      - next_page_cache_password
      - web_rabbit_username
      - web_rabbit_password
    networks:
      - web_net
  first-page-cache:
    image: friedrice2/myaku_redis.first-page-cache:1.0.0
    volumes:
      - type: volume
        source: first_page_cache_data
        target: /data
    environment:
      MYAKU_FIRST_PAGE_CACHE_PASSWORD_FILE: /run/secrets/first_page_cache_password
    secrets:
      - first_page_cache_password
    networks:
      - crawler_net
      - web_net
  next-page-cache:
    image: friedrice2/myaku_redis.next-page-cache:1.0.0
    volumes:
      - type: volume
        source: next_page_cache_data
        target: /data
    environment:
      MYAKU_NEXT_PAGE_CACHE_PASSWORD_FILE: /run/secrets/next_page_cache_password
    secrets:
      - next_page_cache_password
    networks:
      - crawler_net
      - web_net
  reverseproxy:
    image: friedrice2/myaku_nginx.reverseproxy:1.2.0
    volumes:
      - type: volume
        source: reverseproxy_log
        target: /nginx_log
    environment:
      MYAKUWEB_HOST: web
      MYAKUWEB_ALLOWED_HOSTS_FILE: /myakuweb_allowed_hosts
    configs:
      - myakuweb_allowed_hosts
    networks:
      - web_net
  crawldb:
    image: friedrice2/myaku_mongo.crawldb:1.1.2
    volumes:
      - type: volume
        source: crawldb_datadb
        target: /data/db

      - type: volume
        source: crawldb_configdb
        target: /data/configdb
    environment:
      MYAKU_CRAWLDB_NAME: myaku
      MONGO_INITDB_DATABASE: myaku
      MONGO_INITDB_ROOT_USERNAME_FILE: /run/secrets/crawldb_root_username
      MONGO_INITDB_ROOT_PASSWORD_FILE: /run/secrets/crawldb_root_password
      MYAKU_CRAWLDB_BACKUP_USERNAME_FILE: /run/secrets/crawldb_backup_username
      MYAKU_CRAWLDB_BACKUP_PASSWORD_FILE: /run/secrets/crawldb_backup_password
      MYAKU_CRAWLDB_CRAWLER_USERNAME_FILE: /run/secrets/crawldb_crawler_username
      MYAKU_CRAWLDB_CRAWLER_PASSWORD_FILE: /run/secrets/crawldb_crawler_password
      MYAKU_CRAWLDB_WEB_USERNAME_FILE: /run/secrets/crawldb_web_username
      MYAKU_CRAWLDB_WEB_PASSWORD_FILE: /run/secrets/crawldb_web_password
    secrets:
      - crawldb_root_username
      - crawldb_root_password
      - crawldb_backup_username
      - crawldb_backup_password
      - crawldb_crawler_username
      - crawldb_crawler_password
      - crawldb_web_username
      - crawldb_web_password
    networks:
      - web_net
      - crawler_net
  crawldb_backup:
    image: friedrice2/mongobackup:2.0.3_4.2.0
    volumes:
      - type: volume
        source: crawldb_backup_log
        target: /mongobackup/log
    environment:
      # A cron schedule of "#" will comment out the line for the backup job in
      # the crontab file so that it will not run while doing development.
      DB_BACKUP_CRON_SCHEDULE: "#"
      DB_USERNAME_FILE: /run/secrets/crawldb_backup_username
      DB_PASSWORD_FILE: /run/secrets/crawldb_backup_password
      AWS_ACCESS_KEY_ID_FILE: /run/secrets/aws_access_key_id
      AWS_SECRET_ACCESS_KEY_FILE: /run/secrets/aws_secret_access_key
      BACKUP_CONFIG_FILE: /mongo_backup_to_s3.yml
    secrets:
      - crawldb_backup_username
      - crawldb_backup_password
      - aws_access_key_id
      - aws_secret_access_key
    configs:
      - mongo_backup_to_s3.yml
    networks:
      - crawler_net

volumes:
  crawler_log:
  rescore_log:
  web_log:
  web_worker_log:
  first_page_cache_data:
  next_page_cache_data:
  reverseproxy_log:
  crawldb_datadb:
  crawldb_configdb:
  crawldb_backup_log:

configs:
  myakuweb_allowed_hosts:
    file: ./dev_configs/myakuweb_allowed_hosts_DEVUSEONLY.txt
  mongo_backup_to_s3.yml:
    file: ./dev_configs/mongo_backup_to_s3_DEVUSEONLY.yml

secrets:
  crawldb_root_username:
    file: ./dev_secrets/crawldb_root_username_DEVUSEONLY.txt
  crawldb_root_password:
    file: ./dev_secrets/crawldb_root_password_DEVUSEONLY.txt
  crawldb_backup_username:
    file: ./dev_secrets/crawldb_backup_username_DEVUSEONLY.txt
  crawldb_backup_password:
    file: ./dev_secrets/crawldb_backup_password_DEVUSEONLY.txt
  crawldb_crawler_username:
    file: ./dev_secrets/crawldb_crawler_username_DEVUSEONLY.txt
  crawldb_crawler_password:
    file: ./dev_secrets/crawldb_crawler_password_DEVUSEONLY.txt
  crawldb_web_username:
    file: ./dev_secrets/crawldb_web_username_DEVUSEONLY.txt
  crawldb_web_password:
    file: ./dev_secrets/crawldb_web_password_DEVUSEONLY.txt
  web_django_secret_key:
    file: ./dev_secrets/web_django_secret_key_DEVUSEONLY.txt
  aws_access_key_id:
    file: ./dev_secrets/aws_access_key_id_DEVUSEONLY.txt
  aws_secret_access_key:
    file: ./dev_secrets/aws_secret_access_key_DEVUSEONLY.txt
  first_page_cache_password:
    file: ./dev_secrets/first_page_cache_password_DEVUSEONLY.txt
  next_page_cache_password:
    file: ./dev_secrets/next_page_cache_password_DEVUSEONLY.txt
  web_rabbit_username:
    file: ./dev_secrets/web_rabbit_username_DEVUSEONLY.txt
  web_rabbit_password:
    file: ./dev_secrets/web_rabbit_password_DEVUSEONLY.txt

networks:
  web_net:
  crawler_net:
